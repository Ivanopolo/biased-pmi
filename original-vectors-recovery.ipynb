{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as sp_linalg\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import kendalltau\n",
    "%matplotlib inline\n",
    "\n",
    "def lognormal_similarity_seed(rng, V):\n",
    "    return rng.lognormal(mean=1, sigma=1, size=[V, V])\n",
    "\n",
    "def gaussian_mixture_similarity_seed_factory(num_centers=10):\n",
    "    def inner(rng, V):\n",
    "        X, labels = make_blobs(n_samples=V,\n",
    "                   n_features=num_centers,\n",
    "                   centers=num_centers,\n",
    "                   cluster_std=1.0,\n",
    "                   shuffle=False,\n",
    "                   random_state=rng)\n",
    "        \n",
    "        dist = euclidean_distances(X)\n",
    "        \n",
    "        with np.errstate(divide='ignore'):\n",
    "            inv_dist = 1.0 / dist\n",
    "        inv_dist[inv_dist == np.inf] = 0\n",
    "        \n",
    "        inv_dist /= inv_dist.mean()\n",
    "        return inv_dist\n",
    "    return inner\n",
    "\n",
    "def generate_data(V=1000, power_law_alpha=1.0, similarity_seed_fun=lognormal_similarity_seed, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "#     power_law_seed = rng.power(a=power_law_alpha, size=V)\n",
    "    P_ij = np.triu(similarity_seed_fun(rng, V), k=1)\n",
    "#     P_ij *= power_law_seed\n",
    "    P_ij += P_ij.T #P_ij == P_ji\n",
    "    P_ij /= P_ij.sum()\n",
    "\n",
    "    p_i = P_ij.sum(axis=1)\n",
    "    P_i = np.diag(p_i)\n",
    "    P_i_inv = np.diag(1.0 / p_i)\n",
    "    similarities = P_i_inv.dot(P_ij).dot(P_i_inv)\n",
    "\n",
    "    with np.errstate(divide='ignore'):\n",
    "        pmis = np.log(similarities)\n",
    "    pmis[pmis == -np.inf] = 0\n",
    "\n",
    "    assert np.allclose(similarities, similarities.T)\n",
    "    assert np.allclose(similarities.dot(P_i).sum(axis=1), 1)\n",
    "    assert np.allclose(P_ij, P_ij.T)\n",
    "    assert np.allclose(pmis, pmis.T)\n",
    "    assert np.allclose(P_i.sum(), 1)\n",
    "    assert np.allclose(P_ij.sum(), 1)\n",
    "    return P_ij, p_i, similarities, pmis\n",
    "\n",
    "def sample_and_estimate(P_ij, sampling_factor=1.0, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = V**2 * sampling_factor\n",
    "\n",
    "    emp_ij = rng.multinomial(n, P_ij.flatten()).reshape([V, V])\n",
    "    emp_ij = emp_ij / emp_ij.sum()\n",
    "\n",
    "    emp_i = emp_ij.sum(axis=1)\n",
    "    non_zeros = emp_i != 0\n",
    "    emp_ij = emp_ij[non_zeros][:, non_zeros]\n",
    "    emp_i = emp_i[non_zeros]\n",
    "\n",
    "    emp_i_inv = np.diag(1.0 / emp_i)\n",
    "    emp_sim = emp_i_inv.dot(emp_ij).dot(emp_i_inv)\n",
    "\n",
    "    with np.errstate(divide='ignore'):\n",
    "        emp_pmi = np.log(emp_sim)\n",
    "    emp_pmi[emp_pmi == -np.inf] = 0\n",
    "    return emp_pmi, non_zeros\n",
    "\n",
    "def get_ranking(sims):\n",
    "    neighbors = []\n",
    "    for i in range(sims.shape[0]):\n",
    "        neighbors.append(np.argsort(-sims[i]))\n",
    "        \n",
    "    return np.asarray(neighbors)\n",
    "\n",
    "def recall(neighbors1, neighbors2):\n",
    "    intersection = 0.0\n",
    "    for i in range(neighbors1.shape[0]):\n",
    "        intersection += len(set(neighbors1[i]) & set(neighbors2[i]))\n",
    "        \n",
    "    return intersection / (neighbors1.shape[0] * neighbors1.shape[1])\n",
    "\n",
    "def tau(neighbors1, neighbors2):\n",
    "    res = 0.0\n",
    "    for i in range(neighbors1.shape[0]):\n",
    "        tmp, _ = kendalltau(neighbors1[i], neighbors2[i])\n",
    "        res += tmp\n",
    "    return res / neighbors1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num: 1, R: 3, SVD Recall: 0.40531, Cos Recall: 0.86512, SVD Tau: 0.2731, Cos Tau: 0.3123\n",
      "Num: 1, R: 5, SVD Recall: 0.74604, Cos Recall: 0.98997, SVD Tau: 0.2565, Cos Tau: 0.2531\n",
      "Num: 1, R: 10, SVD Recall: 0.99001, Cos Recall: 0.99125, SVD Tau: 0.2087, Cos Tau: 0.0895\n",
      "Num: 10, R: 3, SVD Recall: 0.53772, Cos Recall: 0.8651, SVD Tau: 0.2883, Cos Tau: 0.2885\n",
      "Num: 10, R: 5, SVD Recall: 0.97553, Cos Recall: 0.9902, SVD Tau: 0.3030, Cos Tau: 0.2297\n",
      "Num: 10, R: 10, SVD Recall: 0.99423, Cos Recall: 0.99297, SVD Tau: 0.3248, Cos Tau: 0.0903\n",
      "Num: 100, R: 3, SVD Recall: 0.54038, Cos Recall: 0.89412, SVD Tau: 0.2897, Cos Tau: 0.2877\n",
      "Num: 100, R: 5, SVD Recall: 0.98934, Cos Recall: 0.9908, SVD Tau: 0.3071, Cos Tau: 0.2288\n",
      "Num: 100, R: 10, SVD Recall: 0.9959, Cos Recall: 0.99319, SVD Tau: 0.3626, Cos Tau: 0.0965\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "V = 1000\n",
    "seeded_rank = 10\n",
    "similarity_seed_fun = gaussian_mixture_similarity_seed_factory(seeded_rank)\n",
    "# rank = 5\n",
    "num_neighbors = 100\n",
    "# sampling_factor = 10.0\n",
    "\n",
    "for sampling_factor in [1, 10, 100]:\n",
    "    for rank in [3, 5, 10]:\n",
    "        P_ij, p_i, similarities, pmis = generate_data(V, power_law_alpha=alpha, \n",
    "                                                      similarity_seed_fun=similarity_seed_fun)\n",
    "        \n",
    "        emp_pmi, non_zeros = sample_and_estimate(P_ij, sampling_factor=sampling_factor)\n",
    "        sparse_emp_pmi = scipy.sparse.csr_matrix(emp_pmi)\n",
    "\n",
    "        true_pmis = pmis[non_zeros][:, non_zeros]\n",
    "        true_ranking = get_ranking(true_pmis)\n",
    "\n",
    "        emp_u, emp_s, emp_v = scipy.sparse.linalg.svds(sparse_emp_pmi, k=rank)\n",
    "\n",
    "        # Honest SVD reconstruction-based ranking with -inf on diagonal\n",
    "        svd_sims = emp_u[:, :rank].dot(np.diag(emp_s[:rank])).dot(emp_v[:rank, :])\n",
    "        np.fill_diagonal(svd_sims, -np.inf)\n",
    "        svd_ranking = get_ranking(svd_sims)\n",
    "\n",
    "        # Cosine between rows of eigenvectors with -inf on diagonal\n",
    "        normed_emp_u = normalize(emp_u[:, :rank])\n",
    "        cos_sims = normed_emp_u.dot(normed_emp_u.T)\n",
    "        np.fill_diagonal(cos_sims, -np.inf)\n",
    "        cos_ranking = get_ranking(cos_sims)\n",
    "\n",
    "        svd_recall = recall(true_ranking[:, :num_neighbors], svd_ranking[:, :num_neighbors])\n",
    "        cos_recall = recall(true_ranking[:, :num_neighbors], cos_ranking[:, :num_neighbors])\n",
    "        \n",
    "        svd_tau = tau(true_ranking, svd_ranking)\n",
    "        cos_tau = tau(true_ranking, cos_ranking)\n",
    "        print(f\"Num: {sampling_factor}, R: {rank}, SVD Recall: {svd_recall}, Cos Recall: {cos_recall}, \" + \\\n",
    "             f\"SVD Tau: {svd_tau:.4f}, Cos Tau: {cos_tau:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
